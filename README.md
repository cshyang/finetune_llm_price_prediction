# üìä Fine-tune LLaMA3 for Item Price Prediction:

This project aims to predict **Amazon item prices** using a combination of traditional machine learning models and large language models (LLMs). The objective is to compare the performance of these models and evaluate how **fine-tuning LLMs** like **GPT-4o-mini** and **LLaMA3.1** can improve prediction accuracy.

Additionally, the fine-tuning process is tracked and monitored using Weights & Biases.

## üìö Dataset

We used the McAuley-Lab/Amazon-Reviews-2023 dataset, available on Hugging Face.

### üõ†Ô∏è Models Used

This project utilizes both **traditional machine learning** models and **LLMs**:

Machine Learning Models

	‚Ä¢	Linear Regression
	‚Ä¢	Bag of Words
	‚Ä¢	Word2Vec
	‚Ä¢	Random Forest

Large Language Models (LLMs)

	‚Ä¢	GPT-4o-mini
	‚Ä¢	LLaMA3.1

## üß∞ Tools and Libraries

	‚Ä¢	Jupyter Notebook: For experimentation and model development.
  ‚Ä¢	GoogleColab for GPU finetuning.
  ‚Ä¢	Weights & Biases (W&B): For monitoring the fine-tuning process and tracking model performance.w32
  ‚Ä¢	Huggingface.
  ‚Ä¢	**QLoRA** & **Peft** for LLM finetuning.
  

## üöÄ Results

### Performance Summary

	‚Ä¢	Among the machine learning models, Random Forest + Linear Regression achieved the best performance.
	‚Ä¢	GPT-4o-mini outperformed all other models (including ML models) when used without fine-tuning.

### Fine-Tuning LLMs

	‚Ä¢	GPT-4o-mini fine-tuning:
	  ‚Ä¢	Interestingly, the performance of GPT-4o-mini slightly worsened after fine-tuning.
	‚Ä¢	Possible reasons:
	  ‚Ä¢	Overfitting to the fine-tuning dataset.
	  ‚Ä¢	Loss of generalization due to the fine-tuning process altering the model‚Äôs prior knowledge.
	‚Ä¢ LLaMA3.1 fine-tuning:
	  ‚Ä¢	After fine-tuning, LLaMA3.1 performed better than GPT-4o-mini, showing improved ability to make accurate predictions.
